import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from groq import Groq
import os
from io import StringIO
import json

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Assistente de An√°lise de Dados IA",
    page_icon="ü§ñ",
    layout="wide"
)

# T√≠tulo e descri√ß√£o
st.title("ü§ñ Assistente de An√°lise de Dados Inteligente")
st.markdown("""
Fa√ßa upload de um arquivo CSV ou Excel e converse com seus dados em linguagem natural!
O assistente IA ir√° analisar, visualizar e extrair insights automaticamente.
""")

# Sidebar para configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Input da API Key do Groq
    api_key = st.text_input(
        "üîë Chave API Groq",
        type="password",
        help="Obtenha sua API key em: https://console.groq.com"
    )
    
    st.divider()
    
    # Sele√ß√£o do modelo ATUALIZADA
    model = st.selectbox(
        "üß† Modelo de IA",
        [
            "llama-3.1-8b-instant",         # Mais r√°pido
            "llama-3.2-90b-text-preview",   # Mais poderoso (beta)
            "llama-3.2-1b-preview",         # Leve e r√°pido
            "gemma2-9b-it"                  # Alternativa
        ],
        index=0,
        help="Modelos ativos do Groq - mixtral-8x7b-32768 foi descontinuado"
    )
    
    # Temperatura para criatividade
    temperature = st.slider(
        "üé≠ Temperatura (criatividade)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Valores mais altos = mais criativo, mais baixo = mais focado"
    )
    
    st.divider()
    
    # Exemplo de perguntas
    st.subheader("üí° Exemplos de perguntas:")
    st.markdown("""
    - "Quais s√£o as principais estat√≠sticas descritivas?"
    - "Existe correla√ß√£o entre [coluna1] e [coluna2]?"
    - "Mostre a distribui√ß√£o de [coluna]"
    - "Quais s√£o os outliers nos dados?"
    - "Crie um gr√°fico de linha para [coluna] ao longo do tempo"
    - "Agrupe os dados por [coluna] e calcule m√©dias"
    """)
    
    st.divider()
    st.caption("Powered by Groq & Streamlit")

# Inicializar cliente Groq
@st.cache_resource
def init_groq_client(api_key):
    if api_key and api_key.strip():
        try:
            return Groq(api_key=api_key.strip())
        except Exception as e:
            st.error(f"Erro ao inicializar cliente Groq: {str(e)}")
            return None
    return None

client = init_groq_client(api_key)

# Fun√ß√£o para an√°lise b√°sica do dataset
def analyze_dataframe(df):
    """Realiza an√°lise b√°sica do dataframe"""
    analysis = {
        "shape": df.shape,
        "columns": list(df.columns),
        "dtypes": df.dtypes.astype(str).to_dict(),
        "missing_values": df.isnull().sum().to_dict(),
        "numeric_columns": df.select_dtypes(include=['number']).columns.tolist(),
        "categorical_columns": df.select_dtypes(include=['object', 'category']).columns.tolist(),
        "sample_data": df.head(5).to_dict('records')
    }
    return analysis

# Fun√ß√£o para gerar visualiza√ß√µes autom√°ticas
def generate_auto_visualizations(df, analysis):
    """Gera visualiza√ß√µes autom√°ticas baseadas nos dados"""
    viz_suggestions = []
    
    # Para colunas num√©ricas
    numeric_cols = analysis['numeric_columns']
    
    if len(numeric_cols) >= 1:
        # Histograma para a primeira coluna num√©rica
        try:
            fig = px.histogram(df, x=numeric_cols[0], 
                              title=f"Distribui√ß√£o de {numeric_cols[0]}",
                              nbins=30)
            viz_suggestions.append(("Histograma", fig))
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel criar histograma: {str(e)}")
    
    if len(numeric_cols) >= 2:
        # Scatter plot entre duas colunas num√©ricas
        try:
            fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1],
                           title=f"{numeric_cols[0]} vs {numeric_cols[1]}")
            viz_suggestions.append(("Scatter Plot", fig))
        except:
            pass
    
    # Para colunas categ√≥ricas
    cat_cols = analysis['categorical_columns']
    if cat_cols and numeric_cols:
        # Bar chart de m√©dia por categoria
        try:
            # Escolher coluna categ√≥rica com menos valores √∫nicos para melhor visualiza√ß√£o
            cat_col = min(cat_cols, key=lambda x: df[x].nunique())
            fig = px.bar(df.groupby(cat_col)[numeric_cols[0]].mean().reset_index(),
                        x=cat_col, y=numeric_cols[0],
                        title=f"M√©dia de {numeric_cols[0]} por {cat_col}")
            viz_suggestions.append(("Bar Chart", fig))
        except:
            pass
    
    return viz_suggestions

# Fun√ß√£o para chamar a API Groq
def query_groq(client, model, prompt, data_context, temperature=0.7):
    """Envia consulta para a API Groq"""
    
    system_prompt = f"""Voc√™ √© um assistente especializado em an√°lise de dados.
    
    CONTEXTO DOS DADOS:
    {data_context}
    
    INSTRU√á√ïES:
    1. Analise a pergunta do usu√°rio sobre os dados
    2. Forne√ßa insights baseados nos dados fornecidos
    3. Sugira visualiza√ß√µes relevantes
    4. Seja conciso e direto
    5. Se a pergunta envolver c√°lculos, explique como eles seriam feitos
    6. Se faltarem informa√ß√µes nos dados, explique isso claramente
    
    Responda em portugu√™s brasileiro.
    """
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=1024
        )
        return response.choices[0].message.content
    except Exception as e:
        error_msg = str(e)
        # Tratamento espec√≠fico para modelo descontinuado
        if "model_decommissioned" in error_msg or "mixtral-8x7b-32768" in error_msg:
            return "‚ùå **Erro: O modelo selecionado foi descontinuado.**\n\nüîß **Solu√ß√£o:** Selecione outro modelo na sidebar, como:\n- `llama-3.1-8b-instant` (mais r√°pido)\n- `gemma2-9b-it` (alternativa)"
        elif "authentication" in error_msg.lower():
            return "‚ùå **Erro de autentica√ß√£o.** Verifique se sua API Key do Groq est√° correta e ativa."
        elif "rate limit" in error_msg.lower():
            return "‚ö†Ô∏è **Limite de requisi√ß√µes atingido.** A conta gratuita do Groq tem limites. Tente novamente em alguns minutos."
        else:
            return f"‚ùå **Erro na consulta √† API:** {error_msg}\n\nüí° **Sugest√µes:**\n1. Verifique sua conex√£o com a internet\n2. Tente um modelo diferente\n3. Verifique se a API Key est√° correta"

# √Årea principal da aplica√ß√£o
tab1, tab2, tab3 = st.tabs(["üì§ Upload de Dados", "üìä An√°lise Autom√°tica", "üí¨ Chat com Dados"])

# Tab 1: Upload de dados
with tab1:
    st.header("1. Fa√ßa upload dos seus dados")
    
    uploaded_file = st.file_uploader(
        "Escolha um arquivo CSV ou Excel",
        type=['csv', 'xlsx', 'xls'],
        help="Tamanho m√°ximo: 200MB"
    )
    
    if uploaded_file is not None:
        try:
            # Ler o arquivo baseado na extens√£o
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            # Limpeza b√°sica: remover colunas totalmente vazias
            df = df.dropna(axis=1, how='all')
            
            # Salvar dataframe na session state
            st.session_state['df'] = df
            st.session_state['file_name'] = uploaded_file.name
            
            st.success(f"‚úÖ Arquivo '{uploaded_file.name}' carregado com sucesso!")
            
            # Mostrar preview
            with st.expander("üìã Visualizar dados (primeiras 10 linhas)"):
                st.dataframe(df.head(10), use_container_width=True)
                
            # Mostrar informa√ß√µes b√°sicas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Linhas", df.shape[0])
            with col2:
                st.metric("Colunas", df.shape[1])
            with col3:
                st.metric("Valores ausentes", df.isnull().sum().sum())
            with col4:
                st.metric("Tamanho", f"{uploaded_file.size / 1024:.1f} KB")
                
        except Exception as e:
            st.error(f"Erro ao ler arquivo: {str(e)}")
            st.info("üí° Dica: Verifique se o arquivo est√° no formato correto.")

# Tab 2: An√°lise autom√°tica
with tab2:
    st.header("2. An√°lise Autom√°tica dos Dados")
    
    if 'df' in st.session_state:
        df = st.session_state['df']
        
        # Realizar an√°lise
        analysis = analyze_dataframe(df)
        
        # Layout em colunas
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìã Informa√ß√µes das Colunas")
            columns_df = pd.DataFrame({
                'Coluna': df.columns,
                'Tipo': df.dtypes.values,
                'Valores √önicos': [df[col].nunique() for col in df.columns],
                'Valores Ausentes': df.isnull().sum().values
            })
            st.dataframe(columns_df, use_container_width=True)
        
        with col2:
            st.subheader("üìà Estat√≠sticas Descritivas")
            if analysis['numeric_columns']:
                st.dataframe(df[analysis['numeric_columns']].describe(), 
                           use_container_width=True)
            else:
                st.info("Nenhuma coluna num√©rica encontrada para an√°lise estat√≠stica.")
        
        # Visualiza√ß√µes autom√°ticas
        st.subheader("üé® Visualiza√ß√µes Sugeridas")
        viz_suggestions = generate_auto_visualizations(df, analysis)
        
        if viz_suggestions:
            # Mostrar 2 visualiza√ß√µes por linha
            for i in range(0, len(viz_suggestions), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(viz_suggestions):
                        name, fig = viz_suggestions[i + j]
                        with cols[j]:
                            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Fa√ßa upload de dados com colunas num√©ricas ou categ√≥ricas para visualiza√ß√µes autom√°ticas.")
        
    else:
        st.info("üìÅ Fa√ßa upload de um arquivo na aba 'Upload de Dados' para ver a an√°lise autom√°tica.")

# Tab 3: Chat com dados
with tab3:
    st.header("3. Chat com seus Dados")
    
    if 'df' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, fa√ßa upload de um arquivo na primeira aba para come√ßar a conversar.")
        st.stop()
    
    if not api_key or not api_key.strip():
        st.error("üîë Por favor, insira sua API Key do Groq na sidebar para usar o chat.")
        st.info("üí° Obtenha uma API key gratuita em: https://console.groq.com")
        st.stop()
    
    if client is None:
        st.error("‚ùå N√£o foi poss√≠vel conectar √† API do Groq. Verifique sua API Key.")
        st.stop()
    
    df = st.session_state['df']
    
    # Preparar contexto dos dados
    data_context = f"""
    Dataset: {st.session_state.get('file_name', 'Arquivo carregado')}
    Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas
    Colunas: {', '.join(df.columns.tolist())}
    
    Tipos de dados:
    {df.dtypes.to_string()}
    
    Amostra dos dados (5 primeiras linhas):
    {df.head().to_string()}
    
    Estat√≠sticas descritivas:
    {df.describe().to_string() if not df.select_dtypes(include=['number']).empty else 'Sem colunas num√©ricas'}
    """
    
    # Inicializar hist√≥rico de chat
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": f"üëã Ol√°! Estou pronto para analisar seu dataset '{st.session_state.get('file_name', '')}'. "
                                           f"üìä **Dimens√µes:** {df.shape[0]} linhas √ó {df.shape[1]} colunas\n\n"
                                           f"üîç **Principais colunas:** {', '.join(df.columns.tolist()[:5])}{'...' if len(df.columns) > 5 else ''}\n\n"
                                           f"üí° **O que voc√™ gostaria de saber sobre esses dados?**"}
        ]
    
    # Mostrar hist√≥rico de chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Input do usu√°rio
    if prompt := st.chat_input("Digite sua pergunta sobre os dados..."):
        # Adicionar mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Mostrar indicador de processamento
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ü§î Analisando seus dados...")
            
            try:
                # Chamar API Groq
                response = query_groq(client, model, prompt, data_context, temperature)
                
                # Exibir resposta
                message_placeholder.markdown(response)
            except Exception as e:
                error_msg = f"‚ùå **Erro durante a an√°lise:** {str(e)}\n\nüí° **Sugest√µes:**\n1. Tente um modelo diferente\n2. Verifique sua conex√£o\n3. Reduza o tamanho do dataset"
                message_placeholder.markdown(error_msg)
                response = error_msg
        
        # Adicionar resposta ao hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": response})
    
    # Controles na parte inferior
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üßπ Limpar Conversa", use_container_width=True):
            st.session_state.messages = [
                {"role": "assistant", "content": "Conversa limpa! Como posso ajudar com seus dados agora?"}
            ]
            st.rerun()
    
    with col2:
        if st.button("üîÑ Atualizar Modelo", use_container_width=True, 
                    help="Recarregar com as configura√ß√µes atuais"):
            st.info(f"Usando modelo: {model} com temperatura: {temperature}")
            st.rerun()

# Rodap√©
st.divider()

# Se√ß√£o de ajuda
with st.expander("‚ùì Precisa de ajuda?"):
    st.markdown("""
    ### üîß **Problemas Comuns e Solu√ß√µes:**
    
    1. **Erro 'model_decommissioned':**
       - O modelo `mixtral-8x7b-32768` foi descontinuado
       - Use o `llama-3.1-8b-instant`
    
    2. **Erro de API Key:**
       - Obtenha chave gratuita em [console.groq.com](https://console.groq.com)
       - Copie toda a chave (come√ßa com `gsk_`)
       - N√£o inclua espa√ßos extras
    
    3. **Limite de requisi√ß√µes:**
       - Conta gratuita tem limite de requests por minuto
       - Aguarde alguns segundos e tente novamente
    
    4. **Arquivo n√£o carrega:**
       - Verifique formato (CSV, Excel)
       - Tamanho m√°ximo: 200MB
       - Sem caracteres especiais no nome
    """)

st.caption("""
üîß **Dicas de uso:**
1. Use `llama-3.1-8b-instant` para melhores resultados
2. Comece com perguntas simples como "mostre estat√≠sticas b√°sicas"
3. Ajuste a temperatura: mais baixa para respostas mais precisas
4. Para datasets grandes, use o modelo `llama-3.1-8b-instant` (mais r√°pido)
""")

st.caption(f"üì± Modelo atual: **{model}** | üå°Ô∏è Temperatura: **{temperature}**")
